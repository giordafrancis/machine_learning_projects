{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wine quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two datasets are related to red and white variants of the Portuguese \"Vinho Verde\" wine. \n",
    "\n",
    "Due to privacy and logistic issues, only physicochemical (inputs) and sensory (the output) variables are available (e.g. there is no data about grape types, wine brand, wine selling price, etc.).\n",
    "\n",
    "These datasets can be viewed as classification or regression tasks. The classes are ordered and not balanced (e.g. there are many more normal wines than excellent or poor ones). \n",
    "Outlier detection algorithms could be used to detect the few excellent or poor wines. Also, we are not sure if all input variables are relevant. So it could be interesting to test feature selection methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial Ideas\n",
    "\n",
    "- Create one master dataset with dummy variable red or white\n",
    "- use white dataset for multi-classification problem as first pass with imbalanced classes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_red = Path(\"../data/winequality-red.csv\")\n",
    "filepath_white = Path(\"../data/winequality-white.csv\")\n",
    "assert all([filepath_red.is_file(), filepath_white.is_file()])\n",
    "dataset_red = pd.read_csv(filepath_red, sep=\";\").assign(red = 1)\n",
    "dataset_white = pd.read_csv(filepath_white, sep=\";\").assign(white =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data peek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_white.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_red.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Summary\n",
    "\n",
    "- one integer feature\n",
    "- no null values\n",
    "- same features in both datasets\n",
    "- features might require scaling\n",
    "- several outliers per input features , exception alcohol and density as expected\n",
    "- output class (quality) is imbalanced, CART or ensemble algorithms might perform better; also consider SMOTE method o address this. \n",
    "- output is positively correlated with alcohol\n",
    "- density and residual sugar positively correlated\n",
    "- alcohol and density negatively correlated \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_red.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_white.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_red.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_white.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_white.describe().T\n",
    "# feature scaling should possibly considered; mean value is very different overall for features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_red.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output class balance\n",
    "# output class imbalance\n",
    "dataset_white['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_red['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass review with wine dataset only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (14,8)\n",
    "dataset_white.plot(kind='box', subplots=True, \n",
    "                   layout = (4,4), sharey=False, sharex=False, figsize=figsize);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_white.hist(figsize=figsize);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation\n",
    "corr = dataset_white.iloc[:,:12].corr()\n",
    "corr.style.background_gradient(cmap='coolwarm', axis=None).set_precision(2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation per feature pairs\n",
    "# top 10. \n",
    "melt_corr = dataset_white.corr().assign(cols = dataset_red.columns).melt(id_vars='cols', value_name = 'corr')\n",
    "melt_corr.loc[melt_corr['corr'] != 1].assign(corr_abs = np.abs(melt_corr['corr'])).drop_duplicates('corr').nlargest(10, 'corr_abs').drop('corr_abs', axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate both dataset and create dummy variable\n",
    "dataset  = pd.concat([dataset_red, dataset_white], sort=False).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imbalanced class for predictor variable\n",
    "dataset['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Transformation\n",
    "\n",
    "Creation of 2 prediction class high and low. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_low = dataset['quality'].le(5)\n",
    "cond_high = dataset['quality'].ge(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.loc[cond_high, 'quality_trans'] = 'high'\n",
    "dataset.loc[cond_low, 'quality_trans'] = 'low'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.quality_trans.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop('quality', axis =1)\n",
    "{col: i for i, col in enumerate(dataset.columns)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Some Algorithms\n",
    "Now it is time to create some models of the data and estimate their accuracy on unseen data.\n",
    "Here is what we are going to cover in this step:\n",
    "1. Separate out a validation dataset.\n",
    "2. Setup the test harness to use 10-fold cross-validation.\n",
    "3. Build 5 different models to predict quality\n",
    "4. Select the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = dataset.copy()\n",
    "X = array.iloc[:, 0:13]\n",
    "y= array.iloc[:,13]\n",
    "hold_out_size = 0.2\n",
    "seed = 49\n",
    "X_train, X_hold_out, y_train, y_hold_out = train_test_split(X, y, test_size=hold_out_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spot-check algorithms\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(solver='liblinear')))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "\n",
    "# evaluate each model in turn\n",
    "num_folds = 5\n",
    "scoring = 'roc_auc' \n",
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = RepeatedStratifiedKFold(n_splits=num_folds, random_state=seed)\n",
    "    cv_results = cross_val_score(estimator=model, X= X_train,y= y_train,cv = kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = f\"{name} {cv_results.mean()} +/- ({cv_results.std()})\"\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare performance\n",
    "fig1 = pyplot.figure()\n",
    "fig1.suptitle('Algorithm comparison')\n",
    "ax = fig1.add_subplot(111)\n",
    "pyplot.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problems with multicolinearity between variables for LDA. Let's scale the data and benchmark again with 5 algorithms below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the dataset\n",
    "pipelines = []\n",
    "pipelines.append(('ScaledLR', Pipeline([('Scaler', StandardScaler()),('LR',\n",
    "LogisticRegression(solver='lbfgs', multi_class='ovr'))])))\n",
    "pipelines.append(('ScaledLDA', Pipeline([('Scaler', StandardScaler()),('LDA',\n",
    "LinearDiscriminantAnalysis())])))\n",
    "pipelines.append(('ScaledKNN', Pipeline([('Scaler', StandardScaler()),('KNN',\n",
    "KNeighborsClassifier())])))\n",
    "pipelines.append(('ScaledCART', Pipeline([('Scaler', StandardScaler()),('CART',\n",
    "DecisionTreeClassifier())])))\n",
    "pipelines.append(('ScaledNB', Pipeline([('Scaler', StandardScaler()),('NB',\n",
    "GaussianNB())])))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in pipelines:\n",
    "    kfold = RepeatedStratifiedKFold(n_splits=num_folds, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare performance\n",
    "# some impromevment on distance learning algorithms as KNN\n",
    "fig1 = pyplot.figure()\n",
    "fig1.suptitle('Algorithm comparison')\n",
    "ax = fig1.add_subplot(111)\n",
    "pyplot.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble Methods\n",
    "\n",
    "Four Ensemble methods are to be used here AdaBoost, Gradient Boosting from boosting methods and Random Forest and Extra Trees for bagging methods. \n",
    "We will use the same test harness as before, 10-fold cross validation. No data standardization\n",
    "is used in this case because all four ensemble algorithms are based on decision trees that are\n",
    "less sensitive to data distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensembles\n",
    "ensembles = []\n",
    "ensembles.append(('AB', AdaBoostClassifier()))\n",
    "ensembles.append(('GBM', GradientBoostingClassifier()))\n",
    "ensembles.append(('RF', RandomForestClassifier(n_estimators=100)))\n",
    "ensembles.append(('ET', ExtraTreesClassifier(n_estimators=100)))\n",
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in ensembles:\n",
    "    kfold = RepeatedStratifiedKFold(n_splits=num_folds, random_state=seed)\n",
    "    cv_results = cross_val_score(estimator=model, X=X_train, y=y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = f\" {name} :: {cv_results.mean()} ({cv_results.std()})\"\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare figures\n",
    "fig = pyplot.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "fig.suptitle('Ensemble Algorithm Comparison')\n",
    "ax.set_xticklabels(names)\n",
    "pyplot.boxplot(results);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm Tunning\n",
    "\n",
    "Based on above results I've decided to tune the Extra Trees Classifier. n_estimators was the parameter used for tunning. No data transform is used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators' : np.array([i for i in range(50,251,100)])}\n",
    "model = ExtraTreesClassifier(random_state=seed)\n",
    "kfold = RepeatedStratifiedKFold(n_splits=num_folds, random_state=seed)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "print(f\"Best::{grid_result.best_score_, grid_result.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, std, param in zip(means, stds, params):\n",
    "    print(f\"{mean}, ({std}), {param}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finalize the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using an Extra Trees Classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ExtraTreesClassifier(n_estimators=250)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions = model.predict(X_hold_out)\n",
    "\n",
    "print(accuracy_score(y_hold_out, predictions))\n",
    "print(confusion_matrix(y_hold_out, predictions))\n",
    "print(classification_report(y_hold_out, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model was able to catch 81% of all positive classifications (F1 score)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
